---
title: "视觉语言模型"
url: "https://docs.jiekou.ai/docs/model/visual.md"
crawled_at: "2026-02-26T23:31:33.765147"
---

Published Time: Thu, 26 Feb 2026 15:31:33 GMT

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.jiekou.ai/llms.txt
> Use this file to discover all available pages before exploring further.

# 视觉语言模型

export const VisionModels = () => {
  if (typeof document === "undefined") {
    return null;
  } else {
    let attempts = 0;
    const maxAttempts = 50;
    const INIT_DISPLAY_COUNT = 3;
    const interval = setInterval(() => {
      const clientComponent = document.getElementById("vision-models");
      if (clientComponent && window.jiekouRemoteData.llmModels.status === 'loaded') {
        const modelList = window.jiekouRemoteData.llmModels.data.filter(model => {
          return (model.features || []).includes('vision');
        });
        let displayModels = modelList.slice(0, INIT_DISPLAY_COUNT).map(model => {
          return `*   ${model.id}
`;
        }).join('');
        let showMoreButton = '';
        if (modelList.length > INIT_DISPLAY_COUNT) {
          showMoreButton = `展示更多`;
        }
        clientComponent.innerHTML = `
          
${displayModels}

          ${showMoreButton}
        `;
        document.getElementById('show-more-vision-model-btn')?.addEventListener('click', () => {
          clientComponent.innerHTML = `
            
${modelList.map(model => { return `*   ${model.id}
`; }).join('')}

          `;
        });
        clearInterval(interval);
      }
      attempts++;
      if (attempts >= maxAttempts) {
        clearInterval(interval);
      }
    }, 200);
    return ;
  }
};

## 功能介绍

视觉语言模型（Vision-Language Model, VLM）是一类同时支持图像与文本输入的多模态大模型，具备对图像内容的理解与跨模态信息处理能力。模型能够基于图片与文本的组合信息，输出高质量的响应内容，广泛应用于图像识别、内容理解、智能问答等场景。

### 典型应用场景

* **图像内容识别与描述**：自动识别图片中的物体、颜色、场景与空间关系，生成自然语言描述。
* **图文综合理解**：结合图像与文本输入，实现上下文相关的多轮对话与复杂任务响应。
* **视觉辅助问答**：可作为 OCR 工具补充，识别图像中嵌入的文本信息并完成问答。
* **未来拓展应用**：适用于智能视觉助手、机器人感知、增强现实等交互场景。

## API 调用说明

调用视觉语言模型需通过 `/chat/completions` 接口，支持图文混合输入。

### 图片处理参数

通过 `detail` 字段设置图像处理精度，支持以下选项：

* `high`：高分辨率，保留更多细节，适合精细化任务。
* `low`：低分辨率，处理速度快，适合实时响应。
* `auto`：系统自动选择合适模式。

### 消息格式示例

#### URL 图片形式

```json  theme={null}
{
  "role": "user",
  "content": [
    {
      "type": "image_url",
      "image_url": {
        "url": "https://example.com/image.png",
        "detail": "high"
      }
    },
    {
      "type": "text",
      "text": "请描述图片中的场景。"
    }
  ]
}
```

#### Base64 图片形式

```json  theme={null}
{
  "role": "user",
  "content": [
    {
      "type": "image_url",
      "image_url": {
        "url": "data:image/jpeg;base64,{base64_image}",
        "detail": "low"
      }
    },
    {
      "type": "text",
      "text": "图片中有哪些文字内容？"
    }
  ]
}
```

### Base64 图像编码示例代码（Python）

```python  theme={null}
import base64
from PIL import Image
import io

def image_to_base64(image_path):
    with Image.open(image_path) as img:
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

base64_image = image_to_base64("path/to/your/image.jpg")
```

## 多图模式

支持发送多张图片与文本共同作为输入，建议最多两张以获得更佳性能与理解效果。

```json  theme={null}
{
  "role": "user",
  "content": [
    {
      "type": "image_url",
      "image_url": {
        "url": "https://example.com/image1.png"
      }
    },
    {
      "type": "image_url",
      "image_url": {
        "url": "data:image/jpeg;base64,{base64_image}"
      }
    },
    {
      "type": "text",
      "text": "比较这两张图片的共同特征。"
    }
  ]
}
```

## 支持模型

以下为当前平台支持的视觉语言模型（VLM）：

 ## 计费方式 视觉语言模型的图像输入将转换为 Tokens 与文本共同计算调用费用： * 每个模型的图像 Token 估算规则略有不同； * 详细的计费标准可在对应模型介绍页中查看。 ## API 调用示例代码 ### 单图像描述 ```python theme={null} from openai import OpenAI client = OpenAI(api_key="YOUR_KEY", base_url="https://api.jiekou.ai/openai") response = client.chat.completions.create( model="qwen/qwen2.5-vl-72b-instruct", messages=[ { "role": "user", "content": [ {"type": "image_url", "image_url": {"url": "https://example.com/cityscape.jpg"}}, {"type": "text", "text": "描述图片中的主要建筑物。"} ] } ], stream=True ) for chunk in response: print(chunk.choices[0].delta.content or "", end="", flush=True) ``` ### 多图像对比分析 ```python theme={null} response = client.chat.completions.create( model="qwen/qwen2.5-vl-72b-instruct", messages=[ { "role": "user", "content": [ {"type": "image_url", "image_url": {"url": "https://example.com/product1.jpg"}}, {"type": "image_url", "image_url": {"url": "https://example.com/product2.jpg"}}, {"type": "text", "text": "请对比一下这两个产品的主要区别。"} ] } ], stream=True ) for chunk in response: print(chunk.choices[0].delta.content or "", end="", flush=True) ``` ## 常见问题与说明 * 图像分辨率与清晰度会影响模型识别准确率，推荐使用清晰图源。 * Base64 编码体积较大，建议图片不超过 1MB。 * 如遇问题请参考平台开发者文档或提交工单获取支持。
